{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD212: Graph mining\n",
    "\n",
    "## Lab 7: Graph neural networks\n",
    "\n",
    "\n",
    "In this lab, you will learn to train and use graph neural networks (GNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.nn import SAGEConv\n",
    "from dgl import function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.data import load_netset\n",
    "from sknetwork.classification import DirichletClassifier\n",
    "from sknetwork.embedding import Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the following graphs (see the [NetSet](https://netset.telecom-paris.fr/) collection for details):\n",
    "* Cora (directed graph + bipartite graph)\n",
    "* WikiVitals (directed graph + bipartite graph)\n",
    "\n",
    "Both graphs have ground-truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "cora = load_netset('cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "wikivitals = load_netset('wikivitals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As GNN must be trained on a specific task (e.g., node classification), we need to split the set of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(n_nodes, test_ratio=0.1, val_ratio=0.1, seed=None):\n",
    "    \"\"\"Split the nodes into train / test / validation sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes: int\n",
    "        Number of nodes.\n",
    "    test_ratio: float\n",
    "        Test ratio.\n",
    "    val_ratio: float\n",
    "        Validation ratio.\n",
    "        The sum of test_ratio and validation_ratio cannot exceed 1.\n",
    "    seed: int\n",
    "        Random seed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    train: numpy array\n",
    "        Boolean mask (train set)\n",
    "    test: numpy array\n",
    "        Boolean mask (test set)\n",
    "    val: numpy array\n",
    "        Boolean mask (validation set)\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # test\n",
    "    index = np.random.choice(n_nodes, int(np.ceil(n_nodes * test_ratio)), replace=False)\n",
    "    test = np.zeros(n_nodes, dtype=bool)\n",
    "    test[index] = 1\n",
    "    \n",
    "    # validation\n",
    "    index = np.random.choice(np.argwhere(~test).ravel(), int(np.ceil(n_nodes * val_ratio)), replace=False)\n",
    "    val = np.zeros(n_nodes, dtype=bool)\n",
    "    val[index] = 1\n",
    "    \n",
    "    # train\n",
    "    train = np.ones(n_nodes, dtype=bool)\n",
    "    train[test] = 0\n",
    "    train[val] = 0\n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Deep Graph Library is based on PyTorch and uses tensors.\n",
    "\n",
    "We here transform the Cora dataset into the appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations between scientific papers\n",
    "adjacency = cora.adjacency\n",
    "# category of papers\n",
    "labels = cora.labels\n",
    "# using keywords of scientific papers as features\n",
    "features = cora.biadjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6]), array([351, 217, 418, 818, 426, 298, 180]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.from_scipy(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dgl.heterograph.DGLHeteroGraph"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor(labels).long()\n",
    "features = torch.Tensor(features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = len(labels)\n",
    "train, test, val = split_train_test_val(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.Tensor(train).bool()\n",
    "test = torch.Tensor(test).bool()\n",
    "val = torch.Tensor(val).bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple graph neural network with 2 layers and a ReLU activation function inbetween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output, dim_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(dim_input, dim_hidden, 'mean')\n",
    "        self.conv2 = SAGEConv(dim_hidden, dim_output, 'mean')\n",
    "        \n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(graph, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the layer SAGEConv on the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model, features, labels):\n",
    "    dim_input = features.shape[1]\n",
    "    dim_output = len(labels.unique())\n",
    "    return model(dim_input, dim_output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction before training\n",
    "output = gnn(graph, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(gnn, graph, features, labels, test):\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        output = gnn(graph, features)\n",
    "        labels_pred = torch.max(output, dim=1)[1]\n",
    "        score = f1_score(np.array(labels[test]), np.array(labels_pred[test]), average='micro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gnn, graph, features, labels, train, val, n_epochs=100, verbose=False):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(gnn.parameters(), lr=0.01)\n",
    "    \n",
    "    gnn.train()\n",
    "    scores = []\n",
    "    \n",
    "    for t in range(n_epochs):   \n",
    "        \n",
    "        # forward\n",
    "        output = gnn(graph, features)\n",
    "        logp = nn.functional.log_softmax(output, 1)\n",
    "        loss = nn.functional.nll_loss(logp[train], labels[train])\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluation\n",
    "        score = eval_model(gnn, graph, features, labels, val)\n",
    "        scores.append(score)\n",
    "        \n",
    "        if verbose and t % 5 == 0:\n",
    "            print(\"Epoch {:02d} | Loss {:.3f} | Score {:.3f}\".format(t, loss.item(), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the GNN and give the F1 score of the classification on the test set.\n",
    "* Compare with the score of a classification based on heat diffusion, using the graph only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 2.074 | Score 0.399\n",
      "Epoch 05 | Loss 0.802 | Score 0.768\n",
      "Epoch 10 | Loss 0.376 | Score 0.852\n",
      "Epoch 15 | Loss 0.201 | Score 0.875\n",
      "Epoch 20 | Loss 0.103 | Score 0.863\n",
      "Epoch 25 | Loss 0.058 | Score 0.871\n",
      "Epoch 30 | Loss 0.038 | Score 0.882\n",
      "Epoch 35 | Loss 0.025 | Score 0.878\n",
      "Epoch 40 | Loss 0.018 | Score 0.882\n",
      "Epoch 45 | Loss 0.013 | Score 0.882\n",
      "Epoch 50 | Loss 0.010 | Score 0.878\n",
      "Epoch 55 | Loss 0.008 | Score 0.882\n",
      "Epoch 60 | Loss 0.007 | Score 0.882\n",
      "Epoch 65 | Loss 0.006 | Score 0.886\n",
      "Epoch 70 | Loss 0.005 | Score 0.882\n",
      "Epoch 75 | Loss 0.005 | Score 0.875\n",
      "Epoch 80 | Loss 0.004 | Score 0.875\n",
      "Epoch 85 | Loss 0.004 | Score 0.875\n",
      "Epoch 90 | Loss 0.003 | Score 0.875\n",
      "Epoch 95 | Loss 0.003 | Score 0.875\n"
     ]
    }
   ],
   "source": [
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8228782287822878"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6]), tensor([351, 217, 418, 818, 426, 298, 180]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x seed per cluster\n",
    "clusters = [np.argwhere(labels==label).ravel() for label in set(labels.numpy())]\n",
    "n_seeds = 150\n",
    "seeds = {i: labels.numpy()[i] for cluster in clusters for i in np.random.choice(cluster, n_seeds, replace=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383763837638377"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet = DirichletClassifier()\n",
    "labels_pred_diffusion = dirichlet.fit_transform(adjacency, seeds)\n",
    "f1_score(np.array(labels[test]), np.array(labels_pred_diffusion[test]), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random seeds\n",
    "n_seeds = 1000\n",
    "seeds = {i: labels.numpy()[i] for i in np.random.choice(range(len(labels)), n_seeds,  replace=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7343173431734318"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet = DirichletClassifier()\n",
    "labels_pred_diffusion = dirichlet.fit_transform(adjacency, seeds)\n",
    "f1_score(np.array(labels[test]), np.array(labels_pred_diffusion[test]), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Apply the previous GNN to an empty graph. What is your conclusion?\n",
    "* Compare with the score of a classification based on heat diffusion, using the features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.graph(([], []), num_nodes=len(graph.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(gnn, graph, features, labels, train, val, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785977859778597"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7343173431734318"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirichlet = DirichletClassifier()\n",
    "labels_pred_diffusion = dirichlet.fit_transform(adjacency, seeds)\n",
    "f1_score(np.array(labels[test]), np.array(labels_pred_diffusion[test]), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will know build your own GNN using `dgl` pre-built functions for message passing between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Implement message passing between nodes in a convolutional layer (hint: use `update_all()` function).\n",
    "* Stack your custom layer in a GNN.\n",
    "* Train your GNN on graph and features and give the F1 score of the classification on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.linear = nn.Linear(dim_input, dim_output)\n",
    "        \n",
    "    def forward(self, graph, features):\n",
    "        with graph.local_scope():\n",
    "            h_node = features\n",
    "            # aggregation of neighbors\n",
    "            graph.ndata['node'] = features\n",
    "            graph.update_all(fn.copy_src('node', 'message'), fn.mean('message', 'neighbor'))\n",
    "            h_neighbor = graph.ndata['neighbor']\n",
    "            # sum of embeddings (node + neighbors)\n",
    "            return self.linear(h_node + h_neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden=20):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = ConvLayer(n_input, n_hidden)\n",
    "        self.conv2 = ConvLayer(n_hidden, n_output)\n",
    "        \n",
    "    def forward(self, graph, features):\n",
    "        h = self.conv1(graph, features)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453874538745388"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From graph only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, there are no features available. An option is to consider one-hot encoding of the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Train a GNN considering one-hot encoding of the nodes as features.\n",
    "* Compare with the score of a classification using more complex features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Loss 1.931 | Score 0.148\n",
      "Epoch 05 | Loss 1.829 | Score 0.365\n",
      "Epoch 10 | Loss 1.636 | Score 0.365\n",
      "Epoch 15 | Loss 1.369 | Score 0.365\n",
      "Epoch 20 | Loss 1.054 | Score 0.365\n",
      "Epoch 25 | Loss 0.738 | Score 0.365\n",
      "Epoch 30 | Loss 0.468 | Score 0.365\n",
      "Epoch 35 | Loss 0.272 | Score 0.365\n",
      "Epoch 40 | Loss 0.151 | Score 0.365\n",
      "Epoch 45 | Loss 0.084 | Score 0.365\n",
      "Epoch 50 | Loss 0.049 | Score 0.365\n",
      "Epoch 55 | Loss 0.031 | Score 0.365\n",
      "Epoch 60 | Loss 0.022 | Score 0.365\n",
      "Epoch 65 | Loss 0.016 | Score 0.365\n",
      "Epoch 70 | Loss 0.013 | Score 0.362\n",
      "Epoch 75 | Loss 0.011 | Score 0.351\n",
      "Epoch 80 | Loss 0.009 | Score 0.343\n",
      "Epoch 85 | Loss 0.008 | Score 0.343\n",
      "Epoch 90 | Loss 0.008 | Score 0.354\n",
      "Epoch 95 | Loss 0.007 | Score 0.354\n"
     ]
    }
   ],
   "source": [
    "features = torch.eye(cora.adjacency.shape[0])\n",
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2693726937269373"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikivitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Train a GNN on Wikivitals using spectral embedding of the bipartite graph as features.\n",
    "* Compare with the classification based on heat diffusion (either on the directed graph or the bipartite graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = wikivitals.adjacency\n",
    "biadjacency = wikivitals.biadjacency\n",
    "labels = wikivitals.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10011x10011 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 824999 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.from_scipy(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = len(labels)\n",
    "train, test, val = split_train_test_val(n_nodes)\n",
    "\n",
    "train = torch.Tensor(train).bool()\n",
    "test = torch.Tensor(test).bool()\n",
    "val = torch.Tensor(val).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all features\n",
    "labels = torch.Tensor(labels).long()\n",
    "features = torch.Tensor(biadjacency.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10011, 37845])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes too long !!\n",
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral  = Spectral(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce feature space dimension\n",
    "features = torch.Tensor(spectral.fit_transform(biadjacency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)\n",
    "train_model(gnn, graph, features, labels, train, val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696606786427146"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(gnn, graph, features, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926147704590818"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get random seeds\n",
    "n_seeds = 1000\n",
    "seeds = {i: labels.numpy()[i] for i in np.random.choice(range(len(labels)), n_seeds,  replace=False)}\n",
    "\n",
    "dirichlet = DirichletClassifier()\n",
    "labels_pred_diffusion = dirichlet.fit_transform(adjacency, seeds)\n",
    "f1_score(np.array(labels[test]), np.array(labels_pred_diffusion[test]), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* What are the most similar articles to **Vincent van Gogh** in terms of cosine similarity in the embedding learned by the GNN?\n",
    "* List the 20 closest articles to **Cat** and **Dog** in terms of cosine similarity in the embedding space (you may consider the mean vector of **Cat** and **Dog**).\n",
    "* List the 20 closest articles to the category **Mathematics** in terms of cosine similarity in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gnn, graph, features, labels, train, val, n_epochs=100, verbose=False):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(gnn.parameters(), lr=0.01)\n",
    "    \n",
    "    gnn.train()\n",
    "    scores = []\n",
    "    \n",
    "    for t in range(n_epochs):   \n",
    "        \n",
    "        # forward\n",
    "        output = gnn(graph, features)\n",
    "        logp = nn.functional.log_softmax(output, 1)\n",
    "        loss = nn.functional.nll_loss(logp[train], labels[train])\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluation\n",
    "        score = eval_model(gnn, graph, features, labels, val)\n",
    "        scores.append(score)\n",
    "        \n",
    "        if verbose and t % 5 == 0:\n",
    "            print(\"Epoch {:02d} | Loss {:.3f} | Score {:.3f}\".format(t, loss.item(), score))\n",
    "            \n",
    "    return output # Returns output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = init_model(GNN, features, labels)\n",
    "embedding = train_model(gnn, graph, features, labels, train, val, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10011, 11])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = wikivitals.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9540"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(names=='Vincent van Gogh')[0][0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Svetlana Alexievich' 'Snow Country' 'Kazuo Ishiguro' 'Naguib Mahfouz'\n",
      " 'Saul Bellow' 'V. S. Naipaul' 'Duino Elegies' 'Ivan Bunin' 'T. S. Eliot'\n",
      " 'Ismail Kadare']\n"
     ]
    }
   ],
   "source": [
    "similarities = emb.dot(emb[idx])\n",
    "print(names[np.argsort(-similarities)[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Svetlana Alexievich' 'Snow Country' 'Kazuo Ishiguro' 'Naguib Mahfouz'\n",
      " 'Saul Bellow' 'Duino Elegies' 'V. S. Naipaul' 'Leaves of Grass'\n",
      " 'To the Lighthouse' 'Ismail Kadare']\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(names=='Pablo Picasso')[0][0]\n",
    "similarities = emb.dot(emb[idx])\n",
    "print(names[np.argsort(-similarities)[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1497: 'Cat', 2468: 'Dog'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:name for i, name in enumerate(names) if name == 'Cat' or name == 'Dog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [1497, 2468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Puya (plant)' 'Solidago' 'Anthurium' 'Liliaceae' 'Bromeliaceae'\n",
      " 'Iridaceae' 'Araceae' 'Apocynaceae' 'Gladiolus' 'Campanulaceae'\n",
      " 'Hypericum' 'Primulaceae' 'Amanita phalloides' 'True frog' 'Hylidae'\n",
      " 'Melastomataceae' 'Mushroom poisoning' 'Agaricus' 'Root canal'\n",
      " 'Vascular cambium']\n"
     ]
    }
   ],
   "source": [
    "sim = emb.dot(np.mean(emb[target], axis=0))\n",
    "print(names[np.argsort(-sim)[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5735: 'Mathematics'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:name for i,name in enumerate(names) if name == 'Mathematics'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = wikivitals.names_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mathematics'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carl Gustav Jacob Jacobi' \"Cauchy's integral formula\"\n",
      " 'Algebraic number field' 'Del' 'Implicit function'\n",
      " 'Alexander Grothendieck' 'Charles Hermite' 'Niels Henrik Abel'\n",
      " 'Partial derivative' 'Joseph Fourier' \"Euler's formula\"\n",
      " 'Module (mathematics)' 'Commutative ring' 'Riemann hypothesis'\n",
      " 'Multiple integral' 'Prime number theorem' \"Laplace's equation\"\n",
      " \"Euler's identity\" 'Homological algebra' 'Inverse function']\n"
     ]
    }
   ],
   "source": [
    "sim = emb.dot(np.mean(emb[labels == label], axis=0))\n",
    "print(names[np.argsort(-sim)[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sknGNN",
   "language": "python",
   "name": "skngnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
